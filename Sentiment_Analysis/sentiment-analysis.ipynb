{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport nltk\nimport torch\nfrom torch import nn\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T22:00:27.936824Z","iopub.execute_input":"2021-08-24T22:00:27.937229Z","iopub.status.idle":"2021-08-24T22:00:30.324145Z","shell.execute_reply.started":"2021-08-24T22:00:27.93715Z","shell.execute_reply":"2021-08-24T22:00:30.322773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NOTE, THIS SESSION IS SET UP TO RUN BIDERCTIONAL LSTM:\n\n# IN ORDER TO RUN RNN: \n    #1. UNCOMMENT self.encoder = nn.RNN() AND COMMENT SIBLING VARIABLE\n    #2. UNCOMMENT output, hidden = self.encoder(embeddings) AND COMMENT SIBLING VARIABLE\n    #3. UNCOMMENT net = SimpleRNN(vocab, 100, 256, 1, 1) AND COMMENT SIBLING VARIABLE\n\n# IN ORDER TO RUN LSTM: \n    #1. UNCOMMENT net = SimpleRNN(vocab, 100, 256, 1, 1) AND COMMENT SIBLING VARIABLE\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:30.325636Z","iopub.execute_input":"2021-08-24T22:00:30.325996Z","iopub.status.idle":"2021-08-24T22:00:30.329946Z","shell.execute_reply.started":"2021-08-24T22:00:30.325957Z","shell.execute_reply":"2021-08-24T22:00:30.329033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n#print(\"Using {} device\".format(device))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T20:18:24.177904Z","iopub.execute_input":"2021-08-19T20:18:24.178244Z","iopub.status.idle":"2021-08-19T20:18:24.190933Z","shell.execute_reply.started":"2021-08-19T20:18:24.178214Z","shell.execute_reply":"2021-08-19T20:18:24.190062Z"}}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:30.332075Z","iopub.execute_input":"2021-08-24T22:00:30.332523Z","iopub.status.idle":"2021-08-24T22:00:30.3944Z","shell.execute_reply.started":"2021-08-24T22:00:30.332486Z","shell.execute_reply":"2021-08-24T22:00:30.393561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = pd.read_csv('../input/selective-stock-headlines-sentiment/Project6500.csv')\nglove = pd.read_csv('../input/global-vector/glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n#print(d['datetime'].dtype)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:30.397769Z","iopub.execute_input":"2021-08-24T22:00:30.398072Z","iopub.status.idle":"2021-08-24T22:00:42.339177Z","shell.execute_reply.started":"2021-08-24T22:00:30.398045Z","shell.execute_reply":"2021-08-24T22:00:42.337881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d['datetime'] = d['datetime'].astype(str).str[:10]\n\n# convert to date type the column transforming the errors into Null values\nd['datetime'] = pd.to_datetime(d['datetime'], errors='coerce')\n#Drop rows with Null value\nd.dropna()\nd = d.sort_values(by='datetime')\ntd = d.copy()\n\n#train sample\nrg = (d['datetime'] <= '2019-08-30')\nd = d.loc[rg]\n\n#test sample\ntrg = (td['datetime'] > '2019-08-30')\ntd = td.loc[trg]\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:42.340486Z","iopub.execute_input":"2021-08-24T22:00:42.340811Z","iopub.status.idle":"2021-08-24T22:00:42.421666Z","shell.execute_reply.started":"2021-08-24T22:00:42.340776Z","shell.execute_reply":"2021-08-24T22:00:42.420657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assign values to label and text arrays\n\nlabel = []\ntext = []\nfor i in range(len(d)):\n    text.append(d.iloc[i][1])\n    label.append(d.iloc[i][3])\n\n    \ntest_text = [] \ntest_label = []\nfor i in range(len(td)):\n    test_text.append(td.iloc[i][1])\n    test_label.append(td.iloc[i][3])\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:42.423186Z","iopub.execute_input":"2021-08-24T22:00:42.423517Z","iopub.status.idle":"2021-08-24T22:00:45.631427Z","shell.execute_reply.started":"2021-08-24T22:00:42.423471Z","shell.execute_reply":"2021-08-24T22:00:45.630566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a bit of text cleaning\nlistOfWords = []\ndef transformer(text):\n    for num, sent in enumerate(text):\n        sent = re.sub('[^a-zA-z]+', ' ', sent).lower()\n        tokens = nltk.word_tokenize(sent)\n        for t in tokens:\n            listOfWords.append(t)\n        text.insert(num, tokens)\n        text.pop(num+1)\n\n# get the list of words for both test and train data\ntransformer(test_text)\ntestListOfWords = listOfWords\nlistOfWords = []\ntransformer(text)\n\n#num of unique words\nuniqueWrds = set(listOfWords)\nvocab = len(set(listOfWords))\nprint(vocab)\n\nlen(listOfWords)//(10*30)\n#num of unique labels\nclasses = len(set(label))\n\n\nindex_to_wrd = dict(enumerate(uniqueWrds))\n\n\nword_to_index = {i[1] : i[0] for i in index_to_wrd.items()}\n\n\n\n# Total number of words\nencoded = np.array([word_to_index[wrd] for wrd in listOfWords])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:45.633384Z","iopub.execute_input":"2021-08-24T22:00:45.633632Z","iopub.status.idle":"2021-08-24T22:00:47.257585Z","shell.execute_reply.started":"2021-08-24T22:00:45.633607Z","shell.execute_reply":"2021-08-24T22:00:47.256797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def findMaxLen():\n    list_len = [len(l) for l in text]\n    return max(list_len)\n#print(findMaxLen())","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:47.258808Z","iopub.execute_input":"2021-08-24T22:00:47.259172Z","iopub.status.idle":"2021-08-24T22:00:47.263884Z","shell.execute_reply.started":"2021-08-24T22:00:47.259136Z","shell.execute_reply":"2021-08-24T22:00:47.262878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_labels is number of unique words\ndef one_hot_encode(arr, n_labels):\n\n   \n    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.int64)\n    \n    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n    \n    one_hot = one_hot.reshape((*arr.shape, n_labels))\n    \n    return one_hot","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:47.267084Z","iopub.execute_input":"2021-08-24T22:00:47.267447Z","iopub.status.idle":"2021-08-24T22:00:47.274176Z","shell.execute_reply.started":"2021-08-24T22:00:47.267395Z","shell.execute_reply":"2021-08-24T22:00:47.273238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#num_batches = len(text)//(sentence_length*num_seqs)\n    \n\ndef batches(text, label, num_seqs=32):\n\n    counter = 0\n    #create empty arrays with the specified number of columns \n    x = np.array([], dtype=int).reshape(0, findMaxLen())\n    y = np.array([], dtype=int).reshape(0,1)\n    \n    for sent, l in zip(text, label):\n        # create a np array with zeros with length 30\n        tmp1 = np.zeros((findMaxLen()), dtype=int)\n        #tmp1 = np.random.randint(0, high=vocab,size=findMaxLen(), dtype=int)\n        #create a 1d array\n        tmp2 = np.atleast_1d(np.array(l))\n        \n        for ind, wrd in enumerate(sent):\n            if wrd in uniqueWrds and ind < 30:\n                tmp1[ind] = word_to_index[wrd]\n        # the arrays to the empty arrays\n        x = np.vstack([x, tmp1])\n        y = np.vstack([y, tmp2])\n        counter +=1\n        if counter == num_seqs:\n            yield x, np.squeeze(y,1)\n            counter = 0\n            x = np.array([], dtype=int).reshape(0, findMaxLen())\n            y = np.array([], dtype=int).reshape(0,1)\n      ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:47.275679Z","iopub.execute_input":"2021-08-24T22:00:47.276259Z","iopub.status.idle":"2021-08-24T22:00:47.285958Z","shell.execute_reply.started":"2021-08-24T22:00:47.276225Z","shell.execute_reply":"2021-08-24T22:00:47.285236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dictionary of word to embedding array\nembedding_dict = {key : val.values for key, val in glove.T.items()}\n\n#Create a matrix for one embedding for each word in the training dataset\ndef embeddingMatrix(word_index, embedding_dict, dimensions):\n    e_matrix = torch.zeros((len(word_index), dimensions))\n    \n    for wrd, ind in word_index.items():\n        if wrd in embedding_dict:\n            e_matrix[ind] = torch.from_numpy(embedding_dict[wrd])\n    \n    return e_matrix\n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:47.287214Z","iopub.execute_input":"2021-08-24T22:00:47.287572Z","iopub.status.idle":"2021-08-24T22:00:56.422553Z","shell.execute_reply.started":"2021-08-24T22:00:47.287534Z","shell.execute_reply":"2021-08-24T22:00:56.421697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = embeddingMatrix(word_to_index, embedding_dict, 100)\nprint(embedding_matrix.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:56.423851Z","iopub.execute_input":"2021-08-24T22:00:56.424205Z","iopub.status.idle":"2021-08-24T22:00:56.496794Z","shell.execute_reply.started":"2021-08-24T22:00:56.42417Z","shell.execute_reply":"2021-08-24T22:00:56.496012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers, dropout):\n        #calling the init function of the RNN parent\n        super(RNN, self).__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n        \n        #self.embedding = nn.Embedding(vocab_size, embed_dim)\n        \n        \n        self.encoder = nn.LSTM(embed_dim,\n                               hidden_dim,\n                               n_layers,\n                               batch_first=True,\n                               dropout=dropout,\n                               bidirectional=True\n                              )\n        \n        #Linear transformation\n        self.decoder = nn.Linear(hidden_dim*2, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    \n    def forward(self, inputs):\n        \n         #output-(batch_size, timesteps, embed_dim)\n        embeddings = self.dropout(self.embedding(inputs))\n        \n       \n        #embeddings = torch.max(embeddings, dim=2)\n       \n        embeddings = embeddings.type(torch.cuda.FloatTensor)\n        #embeddings = embeddings[0].type(torch.cuda.FloatTensor)\n        \n        #output of each timestep\n        #hidden = [num layers * num directions, batch size, hid dim]\n        output, (hidden, cell) = self.encoder(embeddings)\n        \n        merge = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n        \n       \n        output = self.decoder(merge)\n        \n        return output\n        \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:56.498104Z","iopub.execute_input":"2021-08-24T22:00:56.49846Z","iopub.status.idle":"2021-08-24T22:00:56.50793Z","shell.execute_reply.started":"2021-08-24T22:00:56.498423Z","shell.execute_reply":"2021-08-24T22:00:56.506528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleRNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers):\n        #calling the init function of the RNN parent\n        super(SimpleRNN, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        \n        self.encoder = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True)\n        \n        #self.encoder = nn.RNN(embed_dim, hidden_dim, n_layers, batch_first=True)\n        \n        #Linear transformation\n        self.decoder = nn.Linear(hidden_dim, output_dim)\n        \n       \n    \n    def forward(self, inputs):\n        \n        \n        #embeddings[batch_size, timesteps, vocab_size, embed_dim]\n        embeddings = self.embedding(inputs)\n        \n        #embeddings[batch_size, timesteps, embed_dim]\n        #embeddings = torch.max(embeddings, dim=2)\n        \n        embeddings = embeddings.type(torch.cuda.FloatTensor)\n        #embeddings = embeddings[0].type(torch.cuda.FloatTensor)\n        \n        #output represents the concatenation of all hidden states\n        #hidden represents the final hidden state\n        output, (hidden, cell) = self.encoder(embeddings)\n        #output, hidden = self.encoder(embeddings)\n        \n\n        hidden = hidden.squeeze(0)\n        \n        \n        return self.decoder(hidden)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:56.50947Z","iopub.execute_input":"2021-08-24T22:00:56.50986Z","iopub.status.idle":"2021-08-24T22:00:56.520676Z","shell.execute_reply.started":"2021-08-24T22:00:56.509824Z","shell.execute_reply":"2021-08-24T22:00:56.519776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = RNN(vocab, 100, 256, 1, 2, 0.2)\n#net = SimpleRNN(vocab, 100, 256, 1, 1)\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:00:56.521934Z","iopub.execute_input":"2021-08-24T22:00:56.522467Z","iopub.status.idle":"2021-08-24T22:01:01.19304Z","shell.execute_reply.started":"2021-08-24T22:00:56.522431Z","shell.execute_reply":"2021-08-24T22:01:01.19225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binaryAccuracy(pred, target):\n    x = torch.round(torch.sigmoid(pred))\n    #for each target and x value if both are equal than +1 else 0\n    correct = (x == target).float()\n    acc = correct.sum() / len(correct)\n    return acc\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:01:01.194287Z","iopub.execute_input":"2021-08-24T22:01:01.19463Z","iopub.status.idle":"2021-08-24T22:01:01.200225Z","shell.execute_reply.started":"2021-08-24T22:01:01.194593Z","shell.execute_reply":"2021-08-24T22:01:01.198663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, text, label, epochs, lr=0.001):\n    \n    model.train()\n    \n    opt = torch.optim.Adam(model.parameters(), lr=lr)\n    #The BCEWithLogitsLoss criterion carries out both the sigmoid and the binary cross entropy steps\n    criterion = nn.BCEWithLogitsLoss()\n    \n\n    for e in range(epochs+1):\n        if e > 0:\n            \n            print(\"Epoch {}/{}\".format(e, epochs), \n                \"Loss: {}\".format(accumLoss/counter),\n                \"accuracy: {}\".format(accumAcc/counter))\n        counter = 0\n        accumLoss = 0      \n        accumAcc = 0\n        if e > 10:\n            break\n        #h = model.init_hidden(10)\n        for x, y in batches(text, label):\n            \n            #Avoid backpropagating through the entire history\n            #h = tuple([each.data for each in h])\n            \n            #x = one_hot_encode(x, vocab)\n            \n            x = torch.from_numpy(x).to(device)\n            \n            #shape(10,1)\n            output = model(x)\n            \n           \n            y = torch.from_numpy(y)\n           \n            y = torch.unsqueeze(y,1).to(device)\n           \n            \n            loss = criterion(output, y.float())\n            accumLoss += loss\n           \n            acc = binaryAccuracy(output,y)\n            accumAcc += acc\n            \n            #Avoids gradient accumulation this way gradients don't point in the wrong direction\n            opt.zero_grad()\n            #computes the gradients of all the parameters in loss that require gradient \n            loss.backward()\n            #Updates all the parameters based on parameters grad\n            opt.step()\n            \n            \n            counter += 1\n        \n            #print(\"Epoch {}/{}\".format(e+1, epochs), \n            #\"Loss: {}\".format(loss.item()),\n            #\"accuracy: {}\".format(acc))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:01:01.201528Z","iopub.execute_input":"2021-08-24T22:01:01.202017Z","iopub.status.idle":"2021-08-24T22:01:01.214092Z","shell.execute_reply.started":"2021-08-24T22:01:01.201968Z","shell.execute_reply":"2021-08-24T22:01:01.213344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, text, labels):\n    \n    counter = 0\n    acc= 0\n    for x, y in batches(text, test_label):\n        #for i in x:\n           \n            #turn the 1d array into 2d with 1 at the beginning of th array\n            #i = np.expand_dims(i, axis=0)\n       \n        #x = one_hot_encode(x, vocab)\n        \n        inputs = torch.from_numpy(x).to(device)\n        \n        y = torch.from_numpy(y)\n           \n        y = torch.unsqueeze(y,1).to(device)\n        #shape(10,1)\n        outputs = model(inputs)\n        acc += binaryAccuracy(outputs, y)\n        counter += 1\n        \n    print(acc/counter)    \n        #prediction = torch.sigmoid(outputs)\n        #for p in prediction:\n            #if p.round() == 1:\n                #print('positive')\n            #else:\n                #print('negative')\n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:01:01.215407Z","iopub.execute_input":"2021-08-24T22:01:01.215786Z","iopub.status.idle":"2021-08-24T22:01:01.225962Z","shell.execute_reply.started":"2021-08-24T22:01:01.215751Z","shell.execute_reply":"2021-08-24T22:01:01.225192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(net, text, label, 10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:01:01.227225Z","iopub.execute_input":"2021-08-24T22:01:01.227799Z","iopub.status.idle":"2021-08-24T22:01:40.83324Z","shell.execute_reply.started":"2021-08-24T22:01:01.227761Z","shell.execute_reply":"2021-08-24T22:01:40.832328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(net, test_text, test_label)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:01:40.834548Z","iopub.execute_input":"2021-08-24T22:01:40.834977Z","iopub.status.idle":"2021-08-24T22:01:42.908114Z","shell.execute_reply.started":"2021-08-24T22:01:40.834936Z","shell.execute_reply":"2021-08-24T22:01:42.907221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}